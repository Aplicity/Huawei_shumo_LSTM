{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    DFs = []\n",
    "    for fileName in os.listdir(\"train_set\"):\n",
    "        with open(os.path.join('train_set', fileName), \"r\") as fr:\n",
    "            temp_df = pd.read_csv(fr)\n",
    "            DFs.append(temp_df)\n",
    "    df = pd.concat(DFs)\n",
    "    return df\n",
    "\n",
    "# df = load_data()\n",
    "# df.to_csv('source_data.csv', index = None)\n",
    "\n",
    "df = pd.read_csv('source_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成特征\n",
    "### 转换角度为弧度，方便计算机计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Azimuth'] = df['Azimuth'] / 180 * np.pi\n",
    "df['Electrical Downtilt'] = df['Electrical Downtilt'] / 180 * np.pi\n",
    "df['Mechanical Downtilt'] = df['Mechanical Downtilt'] / 180 * np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 是否弱覆盖: is_PCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_PCR'] = df['RSRP'].apply(lambda x : 1 if x < -103 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot 地物类型: Clutter Index_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clutter Index'] = df['Clutter Index'].astype(str)\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目标与发射塔海拔高度差: d_A （米）\n",
    " d_A = 发射机海拔 - 目标海拔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d_A'] = df['Cell Altitude'] - df['Altitude']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 天线离目标有效高度 h_b （米）\n",
    "h_b = 目标与发射塔海拔高度差 + 发射机相对地面高度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['h_b'] = df['d_A'] + df['Height']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目标与发射机水平距离 ： d （米）\n",
    "d = 5 * sqrt( (Cell_x - x )^2 + (Cell_y - y )^2 ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d'] = 5 * ((df['Cell X'] - df['X'])**2 + (df['Cell Y'] - df['Y'])**2)**0.5 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目标栅格与信号线相对高度 :  d_h_v (米)\n",
    "d_h_v = h_b - d * np.tan( ED + MD)\n",
    "\n",
    "Note : 如果值为正，则天线在目标上方；若为负，则在天线下方\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['d_h_v'] = df['h_b'] - df['d'] * np.tan(df['Electrical Downtilt'] + df['Mechanical Downtilt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 天线是否反射才能抵达目标上方 ：is_reflect \n",
    "如果天线在目标下方，则需要反射，即 if d_h_v < 0 : 反射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_reflect'] = df['d_h_v'].apply(lambda x : 1 if x < 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信号线长度 ：L （米）\n",
    "L^2 = d^2 +（d*tan(ED+MD)）^2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['L'] = ( df['d']**2 + (df['d']*np.tan(df['Electrical Downtilt'] + df['Mechanical Downtilt']))**2 )**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目标栅格离天线距离 ：S (米)\n",
    "S^2 = d^2 + h_b^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['S'] = (df['d']**2 + df['h_b']**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 传播路径损耗：PL （dB）\n",
    "PL = 46.3 + 33.9 * f - 13.82 * log10(h_b) + (44.9 - 6.55*log10(h_b)) * log10(d)\n",
    "\n",
    "* h_b可能为负值，也就是天线的海拔低于目标海拔，取对数时报错。因此在计算时用绝对值计算；0值则用1替换，取对数后得值为0。\n",
    "* d 可能为0，这时候目标与天线在同一栅格，同样用1替代，取对数后得值为0。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp_h_b'] = abs(df['h_b'])\n",
    "df['temp_h_b'] = df['temp_h_b'].replace(0, 1)\n",
    "df['temp_d'] = df['d'].replace(0, 1)\n",
    "\n",
    "df['PL'] = 46.3 + 33.9 * np.log10(df['Frequency Band']) - 13.82 * np.log10(\n",
    "    df['temp_h_b']) + (44.9 - 6.55*np.log10(df['temp_h_b'])) * np.log10(df['temp_d'] / 1000 )\n",
    "\n",
    "df = df.drop(['temp_h_b', 'temp_d'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 理论RSRP ：my_RSRP (dBm)\n",
    "my_RSRP = P - PL\n",
    "\n",
    "Note: P (RS Power)  为射机发射功率,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['my_RSRP'] = df['RS Power'] - df['PL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 发射机服务目标数量 ：N \n",
    "或者说跟目标自己接受同一发射机信号的用户量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_for_CellToTarget(data):\n",
    "    temp_df = data.groupby(\"Cell Index\")['Cell Index'].count().to_frame()\n",
    "    temp_df.columns = ['N']\n",
    "    temp_df[\"Cell Index\"]= temp_df.index\n",
    "    temp_df = temp_df.reset_index(drop = True)\n",
    "    data = pd.merge( data , temp_df, on = 'Cell Index', how = 'left' )\n",
    "    return data\n",
    "\n",
    "df = get_number_for_CellToTarget(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 小区栅格发射机数量 : N_c\n",
    "仔细观察，可以看到有些栅格不止一台发射机"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NumberOfStation_forCell(data):\n",
    "    temp_df = data[[\"Cell Index\", \"Cell X\", \"Cell Y\"]]\n",
    "    temp_df = temp_df.drop_duplicates()\n",
    "    count_data = temp_df.groupby([\"Cell X\", \"Cell Y\"])[\"Cell Index\"].count().to_frame()\n",
    "    count_data.columns = ['N_c']\n",
    "    count_data = count_data.reset_index()\n",
    "    data = pd.merge(data,count_data , on = [\"Cell X\", \"Cell Y\"], how = 'left')\n",
    "    return data\n",
    "\n",
    "df = get_NumberOfStation_forCell(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据清洗\n",
    "### 剔除与数据定义相违数据\n",
    "由于题目地物类型名称的编号对各种建筑有高度规定，比如地物类型编号为10的建筑高度定义为大于60米，因此在数据中可以把该类地物类型建筑高度小于60米的作为异常数据并进行剔除。综合对比所有栅格建筑高度和对应的地物建筑规定定义，共发现1175100个异常数据，占总体数量9.78%。!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_A = (df['Cell Clutter Index'] == 10) & (df['Building Height'] <= 60)\n",
    "mask_B = (df['Cell Clutter Index'] == 11) & (df['Building Height'] < 40)\n",
    "mask_C = (df['Cell Clutter Index'] == 11) & (df['Building Height'] > 60)\n",
    "\n",
    "mask_D = (df['Cell Clutter Index'] == 12) & (df['Building Height'] < 20)\n",
    "mask_E = (df['Cell Clutter Index'] == 12) & (df['Building Height'] > 40)\n",
    "\n",
    "mask_F = (df['Cell Clutter Index'] == 13) & (df['Building Height'] > 20)\n",
    "mask_G = (df['Cell Clutter Index'] == 14) & (df['Building Height'] > 20)\n",
    "\n",
    "mask = mask_A | mask_B | mask_C | mask_D | mask_E | mask_F | mask_G\n",
    "\n",
    "df = df[~mask]\n",
    "\n",
    "del mask_A , mask_B , mask_C , mask_D , mask_E , mask_F , mask_G "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拉依达准则剔除极端数据\n",
    "把RSRP数据取值不在 (mean - 3 * std , mean + 3 * std)范围的剔除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RSRP_mean = df['RSRP'].mean()\n",
    "RSRP_std = df['RSRP'].std()\n",
    "upper_value = RSRP_mean + 3 * RSRP_std\n",
    "lower_value = RSRP_mean - 3 * RSRP_std\n",
    "\n",
    "mask = (df['RSRP'] >= lower_value) & (df['RSRP'] <= upper_value)\n",
    "df = df[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 相关分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is_PCR</td>\n",
       "      <td>-0.635048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PL</td>\n",
       "      <td>-0.332661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my_RSRP</td>\n",
       "      <td>0.329180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>-0.186399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>-0.186380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L</td>\n",
       "      <td>-0.186346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d_h_v</td>\n",
       "      <td>0.164135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is_reflect</td>\n",
       "      <td>-0.090910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Clutter Index_6</td>\n",
       "      <td>0.050520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Building Height</td>\n",
       "      <td>-0.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>N</td>\n",
       "      <td>-0.030339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Clutter Index_12</td>\n",
       "      <td>-0.026635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Clutter Index_8</td>\n",
       "      <td>-0.021389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Clutter Index_11</td>\n",
       "      <td>-0.015044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cell Clutter Index</td>\n",
       "      <td>-0.014761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Clutter Index_2</td>\n",
       "      <td>0.014680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Clutter Index_5</td>\n",
       "      <td>-0.013629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RS Power</td>\n",
       "      <td>-0.012505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Clutter Index_13</td>\n",
       "      <td>-0.012251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Electrical Downtilt</td>\n",
       "      <td>-0.010882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  correlation\n",
       "0                is_PCR    -0.635048\n",
       "1                    PL    -0.332661\n",
       "2               my_RSRP     0.329180\n",
       "3                     d    -0.186399\n",
       "4                     S    -0.186380\n",
       "5                     L    -0.186346\n",
       "6                 d_h_v     0.164135\n",
       "7            is_reflect    -0.090910\n",
       "8       Clutter Index_6     0.050520\n",
       "9       Building Height    -0.048100\n",
       "10                    N    -0.030339\n",
       "11     Clutter Index_12    -0.026635\n",
       "12      Clutter Index_8    -0.021389\n",
       "13     Clutter Index_11    -0.015044\n",
       "14   Cell Clutter Index    -0.014761\n",
       "15      Clutter Index_2     0.014680\n",
       "16      Clutter Index_5    -0.013629\n",
       "17             RS Power    -0.012505\n",
       "18     Clutter Index_13    -0.012251\n",
       "19  Electrical Downtilt    -0.010882"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_to_corr = dict()\n",
    "features = list(df.columns)\n",
    "features.remove('RSRP')\n",
    "features.remove('Cell Index')\n",
    "\n",
    "for col in features:\n",
    "    corr = df[[col, 'RSRP']].corr().get_values()[0,1]\n",
    "    feature_to_corr[col] = corr\n",
    "    \n",
    "data = sorted(feature_to_corr.items(), key = lambda d: abs(d[1]) , reverse = True )\n",
    "data = pd.DataFrame(data = data , columns = ['feature', 'correlation'])\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征数据标准化\n",
    "### 挑选特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 挑选25个特征\n",
    "features = ['Frequency Band', 'RS Power', 'Cell Clutter Index',  'Building Height',\n",
    "             'Clutter Index_10', 'Clutter Index_11', 'Clutter Index_12',\n",
    "            'Clutter Index_13', 'Clutter Index_14', 'Clutter Index_15', 'Clutter Index_2',\n",
    "            'Clutter Index_5', 'Clutter Index_8', 'd_A', 'h_b', 'd', 'd_h_v', 'is_reflect',\n",
    "            'L', 'S', 'PL', 'my_RSRP', 'N', 'N_c', 'is_PCR' ]\n",
    "\n",
    "Xs = np.array(df[features].get_values() , dtype = np.float32)\n",
    "Ys = np.array(df['RSRP'].get_values() , dtype = np.float32)\n",
    "\n",
    "del df\n",
    "\n",
    "# np.save('Xs', Xs)\n",
    "# np.save('Ys', Ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StandardSclaer(xs, ys):\n",
    "    x_mean = xs.mean(axis = 0)\n",
    "    x_std = xs.std(axis = 0 )\n",
    "    y_mean = ys.mean(axis = 0)\n",
    "    y_std = ys.std(axis = 0)\n",
    "    ss_xs = (xs - x_mean) / x_std\n",
    "    ss_ys = (ys - y_mean) / y_std\n",
    "    return ss_xs, ss_ys , x_mean, x_std, y_mean , y_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 功能函数\n",
    "### tran_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trian : test = 7:3\n",
    "def train_test_split():\n",
    "    xs = np.load(\"Xs.npy\")\n",
    "    ys = np.load(\"Ys.npy\") \n",
    "    np.random.seed(1)\n",
    "    np.random.shuffle(xs)\n",
    "    np.random.seed(1)\n",
    "    np.random.shuffle(ys)\n",
    "    train_samples = int(len(xs) * 0.7)\n",
    "    train_xs , train_ys = xs[:train_samples] , ys[:train_samples]\n",
    "    test_xs , test_ys = xs[train_samples:] , ys[train_samples:]\n",
    "    return train_xs , train_ys, test_xs , test_ys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(data_x, data_y,  batch_size, time_step ):\n",
    "    batch_index = []\n",
    "    train_xs , train_ys = [], []\n",
    "    n = len(data_x)\n",
    "    for i in range(n - time_step ):\n",
    "        if i % batch_size == 0:\n",
    "            batch_index.append(i)\n",
    "        x = data_x[i : i+time_step]\n",
    "        y = data_y[i : i+time_step, np.newaxis]\n",
    "        train_xs.append(x.tolist())\n",
    "        train_ys.append(y.tolist())\n",
    "        \n",
    "#     batch_index.append((len(train_xs)-time_step))\n",
    "    return batch_index, train_xs, train_ys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data(data_x , data_y ,  time_step):\n",
    "    \n",
    "    size = (len(data_x) + time_step - 1) // time_step  \n",
    "    test_xs, test_ys = [], []\n",
    "    for i in range(size - 1):\n",
    "        x = data_x[i * time_step:(i + 1) * time_step]\n",
    "        y = data_y[i * time_step:(i + 1) * time_step]\n",
    "        test_xs.append(x.tolist())\n",
    "        test_ys.extend(y)\n",
    "        \n",
    "    test_xs.append((data_x[(i + 1) * time_step:]).tolist())\n",
    "    test_ys.extend((data_y[(i + 1) * time_step:]))\n",
    "    \n",
    "    input_size = len(x[-1])\n",
    "    row = time_step - len(test_xs[-1]) % time_step\n",
    "    test_xs[-1] = np.concatenate((test_xs[-1], np.zeros((row,input_size)) ) ,axis = 0)\n",
    "    test_ys.extend([0] * row)\n",
    "    return test_xs , test_ys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## global_variables_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_unit = 100       #hidden layer units\n",
    "input_size = 25\n",
    "output_size = 1\n",
    "lr = 0.001         #Ñ§Ï°ÂÊ\n",
    "time_step = 3\n",
    "batch_size = 32\n",
    "EPOCHs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.load(\"Xs.npy\")\n",
    "ys = np.load(\"Ys.npy\")\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(xs)\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(ys)\n",
    "# xs = xs[:2000000]\n",
    "# ys = ys[:2000000]\n",
    "xs, ys, x_mean, x_std, y_mean, y_std = StandardSclaer(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('placeholder'):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, time_step, input_size], name = 'X')\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, time_step, output_size], name = 'Y')\n",
    "    inputs = tf.reshape(X,[-1,input_size]) # 换成2D, [batch_size * time_step , input_size]\n",
    "    \n",
    "with tf.name_scope('LSTM'):\n",
    "    # 输入层权重\n",
    "    W_in = tf.Variable(initial_value = tf.random_normal(shape = (input_size ,rnn_unit), mean=0.0, stddev=0.1),\n",
    "                       name = 'W_in')\n",
    "    b_in = tf.Variable(initial_value = tf.zeros(rnn_unit), name = \"b_in\")\n",
    "\n",
    "    input_rnn = tf.matmul(inputs, W_in ) + b_in\n",
    "    input_rnn = tf.reshape(input_rnn,[-1,time_step,rnn_unit]) # 换回3D ,[batch_size , time_step, rnn_unit]\n",
    "    \n",
    "    ## 添加lstm 单元\n",
    "    cell = tf.nn.rnn_cell.BasicLSTMCell(rnn_unit, reuse=tf.AUTO_REUSE)\n",
    "    init_state = cell.zero_state(batch_size,dtype=tf.float32)\n",
    "    output_rnn,final_states = tf.nn.dynamic_rnn(cell, input_rnn, initial_state =init_state, dtype=tf.float32) \n",
    "    outputs = tf.reshape(output_rnn,[-1,rnn_unit]) \n",
    "    \n",
    "    ## 输出层权重\n",
    "    W_out = tf.Variable(initial_value = tf.random_normal(shape = (rnn_unit,1), mean=0.0, stddev=0.1),name = 'W_out')\n",
    "    b_out = tf.Variable(initial_value = tf.zeros(1), name = \"b_out\")\n",
    "    predictions = tf.matmul(outputs, W_out) + b_out\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean( tf.square(tf.reshape(predictions,[-1]) - tf.reshape(Y, [-1] )))\n",
    "\n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# 训练LSTM\n",
    "with tf.Session() as sess:\n",
    "    with tf.variable_scope(name_or_scope='', reuse=tf.AUTO_REUSE):\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        batch_index, xs, ys = get_train_data(xs, ys, batch_size , time_step=3)\n",
    "        for epoch in range(50):\n",
    "            total_loss = 0\n",
    "            for i in range(len(batch_index) - 1 ):\n",
    "                batch_x = xs[batch_index[i]: batch_index[i+1]]\n",
    "                batch_y = ys[batch_index[i]: batch_index[i+1]]\n",
    "                _, curr_loss = sess.run([optimizer, loss], feed_dict={X: batch_x, Y: batch_y})\n",
    "#                 pred = sess.run(predictions , feed_dict = {X: batch_x})\n",
    "\n",
    "#             print(epoch+1)\n",
    "            \n",
    "            # 保存模型\n",
    "        tf.saved_model.simple_save(sess, \"./model_0922/\",\n",
    "                                   inputs = {\"myInput\": X},\n",
    "                                   outputs = {\"myOutput\" : predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "259px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 205,
   "position": {
    "height": "271px",
    "left": "1081px",
    "right": "20px",
    "top": "120px",
    "width": "339px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
